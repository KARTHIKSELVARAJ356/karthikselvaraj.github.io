<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Karthik | AWS Data Engineer</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

<!-- HEADER -->
<header class="header">
  <div class="container header-content">
    <h2>Karthik</h2>
    <nav>
      <a href="#about">About</a>
      <a href="#skills">Skills</a>
      <a href="#projects">Projects</a>
      <a href="#contact">Contact</a>
    </nav>
  </div>
</header>

<!-- HERO -->
<section class="hero">
  <div class="container">
    <h1>AWS Data Engineer</h1>
    <p class="hero-subtitle">
      PySpark • SQL • Airflow • AWS
    </p>
    <p class="hero-desc">
      I design, build, and support scalable data pipelines and ETL workflows
      on AWS with a strong focus on reliability and production systems.
    </p>
  </div>
</section>

<!-- ABOUT -->
<section id="about" class="section">
  <div class="container">
    <h2>About Me</h2>
    <p>
      I am an AWS Data Engineer with hands-on experience in batch and streaming
      data pipelines. I have worked on end-to-end data ingestion, transformation,
      and loading using PySpark, AWS Glue, S3, Lambda, Redshift, and Airflow.
      I also support production systems and resolve pipeline issues efficiently.
    </p>
  </div>
</section>

<!-- SKILLS -->
<section id="skills" class="section bg-light">
  <div class="container">
    <h2>Skills</h2>
    <div class="skills">
      <span>Python</span>
      <span>SQL</span>
      <span>PySpark</span>
      <span>AWS Glue</span>
      <span>S3</span>
      <span>Lambda</span>
      <span>Redshift</span>
      <span>Airflow</span>
      <span>MySQL</span>
      <span>PostgreSQL</span>
    </div>
  </div>
</section>

<!-- PROJECTS -->
<section id="projects" class="section">
  <div class="container">
    <h2>Projects</h2>

    <div class="project-card">
      <h3>SFTP → S3 → MySQL ETL Pipeline</h3>
      <p><strong>Problem:</strong> Manual file ingestion from SFTP caused delays and errors.</p>
      <p><strong>Solution:</strong> Built an automated Python ETL pipeline to ingest files into S3 and load into MySQL.</p>
      <p><strong>Tools:</strong> Python, AWS S3, SQLAlchemy, MySQL</p>
      <p><strong>Outcome:</strong> Reliable daily ingestion with proper logging and error handling.</p>
    </div>

    <div class="project-card">
      <h3>AWS Glue PySpark Data Pipeline</h3>
      <p><strong>Problem:</strong> Large datasets required efficient transformation at scale.</p>
      <p><strong>Solution:</strong> Developed PySpark jobs in AWS Glue to transform and load data into curated tables.</p>
      <p><strong>Tools:</strong> PySpark, AWS Glue, S3</p>
      <p><strong>Outcome:</strong> Improved performance and reduced processing time.</p>
    </div>

  </div>
</section>

<!-- CONTACT -->
<section id="contact" class="section bg-dark">
  <div class="container">
    <h2>Contact</h2>
    <p>Email: your-email@gmail.com</p>
    <p class="links">
      <a href="https://github.com/yourusername" target="_blank">GitHub</a>
      <a href="https://linkedin.com/in/yourprofile" target="_blank">LinkedIn</a>
    </p>
  </div>
</section>

<footer class="footer">
  © 2026 Karthik • AWS Data Engineer
</footer>

</body>
</html>
